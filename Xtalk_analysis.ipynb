{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a47a9a6b-98fe-4e66-b787-a72d32eecb1b",
   "metadata": {},
   "source": [
    "**Cross-Talk Analysis (at NERSC)**\n",
    "===\n",
    "### **Author: Hung-Wei,Liu**\n",
    "\n",
    "First, we import the necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13fbb4ba-5553-4eb7-8114-053cb1a979e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lgdo import lh5\n",
    "from dbetto import Props, TextDB\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af351adf-49ca-48e2-8f10-a160abb7b09d",
   "metadata": {},
   "source": [
    "Next, we set up the path names and file names (for NERSC). We still follow the SOP by extracting the keys from the valid file although we acknowledge the fact that some files are missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a592fdc9-9c4b-4cbd-969a-6eece8341065",
   "metadata": {},
   "outputs": [],
   "source": [
    "period, run = \"p08\", \"r015\"\n",
    "xtc_dir = \"/global/cfs/cdirs/m2676/data/lngs/l200/scratch/crosstalk_data/xtc\"\n",
    "lmeta = TextDB(path=f\"{xtc_dir}/inputs\")\n",
    "\n",
    "valid_file = f\"{xtc_dir}/generated/par/valid_keys/l200-{period}-{run}-valid_xtc.json\"\n",
    "valid_keys = list(Props.read_from(valid_file)[\"valid_keys\"])\n",
    "time_string = valid_keys[0].split(\"-\")[-1]\n",
    "\n",
    "dsp_dir = f\"{xtc_dir}/generated/tier/dsp/xtc/{period}/{run}\"\n",
    "hit_dir = f\"{xtc_dir}/generated/tier/hit/xtc/{period}/{run}\"\n",
    "dsp_list = [f\"{dsp_dir}/{key}-tier_dsp.lh5\" for key in valid_keys]\n",
    "hit_list = [f\"{hit_dir}/{key}-tier_hit.lh5\" for key in valid_keys]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20805ee-62e8-4f5a-b7a2-eaa9096f8c63",
   "metadata": {},
   "source": [
    "The following cell is for removing missing files from the list. It should be removed when the analysis is moved to LNGS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "399fba5e-ac3e-4aa7-96b7-bf2e14b056e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "listed_files = set(os.path.basename(f) for f in hit_list)\n",
    "actual_files = set(os.listdir(hit_dir))\n",
    "non_existent_files = listed_files - actual_files\n",
    "new_hit_list = []\n",
    "for f in hit_list:\n",
    "    if os.path.basename(f) not in non_existent_files:\n",
    "        new_hit_list.append(f)\n",
    "\n",
    "listed_files = set(os.path.basename(f) for f in dsp_list)\n",
    "actual_files = set(os.listdir(dsp_dir))\n",
    "non_existent_files = listed_files - actual_files\n",
    "new_dsp_list = []\n",
    "for f in dsp_list:\n",
    "    if os.path.basename(f) not in non_existent_files:\n",
    "        new_dsp_list.append(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1c2de3-2ba8-4c09-b601-531740a54f20",
   "metadata": {},
   "source": [
    "**Extract detector raw ids through TextDB utilities**\n",
    "---\n",
    "\n",
    "Not all the groups in the hit_files or dsp_files represent actual detectors. We need to extract the raw ids of detectors in order to choose the correct groups to read out later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fd2b6da-3905-45dd-bc4a-27ad493c189c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240108T164446Z\n",
      "[1104000, 1104001, 1104002, 1104003, 1104004, 1104005, 1105600, 1105602, 1105603, 1107202, 1107203, 1107204, 1107205, 1108800, 1108801, 1108802, 1108803, 1108804, 1110402, 1110403, 1110404, 1110405, 1112000, 1112001, 1112002, 1112003, 1112004, 1112005, 1113600, 1113601, 1113602, 1113603, 1113604, 1113605, 1115200, 1115201, 1115202, 1115203, 1115204, 1116801, 1116802, 1116803, 1116804, 1116805, 1118402, 1118403, 1118404, 1118405, 1120000, 1120001, 1120002, 1120003, 1120004, 1120005, 1121600, 1121601, 1121602, 1121603, 1121604, 1121605, 1078400, 1078405, 1080000, 1080001, 1080002, 1080003, 1080004, 1080005, 1081600, 1081601, 1081602, 1081603, 1081604, 1081605, 1083200, 1083201, 1083202, 1083203, 1083204, 1083205, 1084800, 1084801, 1084802, 1084803, 1084804, 1084805, 1086400, 1086401, 1086403, 1086404, 1086405, 1088000, 1088001, 1088002, 1088003, 1088004, 1089600, 1089601, 1089602, 1089603, 1089604]\n",
      "101\n"
     ]
    }
   ],
   "source": [
    "chmap = lmeta.hardware.configuration.channelmaps.on(time_string)\n",
    "print(time_string)\n",
    "geds = [ch for ch in chmap.keys() if chmap[ch]['system']=='geds']\n",
    "chn_id = []\n",
    "for detector in geds:\n",
    "    chn_id.append(chmap[detector]['daq']['rawid'])\n",
    "print(chn_id)\n",
    "print(len(chn_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032126be-16eb-42ac-b54c-1604330579c3",
   "metadata": {},
   "source": [
    "**Step 1: Evaluate Baseline Energy**\n",
    "---\n",
    "For each detector, we should extract the events tagged with ```is_baseline == True``` and evaluate the average baseline energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c629667d-f269-43a1-9f22-48d5935db912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline energy evaluated for the 0th detector.\n",
      "Baseline energy evaluated for the 1th detector.\n",
      "Baseline energy evaluated for the 2th detector.\n",
      "Baseline energy evaluated for the 3th detector.\n",
      "Baseline energy evaluated for the 4th detector.\n",
      "Baseline energy evaluated for the 5th detector.\n",
      "Baseline energy evaluated for the 6th detector.\n",
      "Baseline energy evaluated for the 7th detector.\n",
      "Baseline energy evaluated for the 8th detector.\n",
      "Baseline energy evaluated for the 9th detector.\n",
      "Baseline energy evaluated for the 10th detector.\n",
      "[np.float64(-0.8561009502910173), np.float64(0.1260089599534006), np.float64(-0.17597473657732793), np.float64(0.12999481028573184), np.float64(-0.10079429025586627), np.float64(-0.14909360718160014), np.float64(0.0730498724317248), np.float64(-0.6125733739494743), np.float64(0.9545673601685722), np.float64(-0.2622581141110762), np.float64(0.9913381211596026)]\n"
     ]
    }
   ],
   "source": [
    "baseline_energy = []\n",
    "\n",
    "baseline_iter_limit = 10\n",
    "for j, detector in enumerate(chn_id):\n",
    "    if j > baseline_iter_limit:\n",
    "        break\n",
    "    baseline_energy.append(np.mean(relevant_events(\n",
    "        table_path=f\"ch{detector}/hit/\",\n",
    "        files=new_hit_list,\n",
    "        ene_dataset=\"cuspEmax_ctc_cal\",\n",
    "        flag_datasets=[\"is_baseline\"],\n",
    "        conditions={\"is_baseline\":63})))\n",
    "    print(f\"Baseline energy evaluated for the {j}th detector.\")\n",
    "\n",
    "print(baseline_energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9944f3-0d20-4f2f-b41d-a0b4ca5166dc",
   "metadata": {},
   "source": [
    "**Step 2: Evaluate the cross talk matrix**\n",
    "---\n",
    "First, let's define the cross-talk matrix element:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1e3f62-eaa6-4350-adfe-4d6abd2ad67e",
   "metadata": {},
   "source": [
    "```baseline``` has been evaluated in the previous cell. For E_trig and E_response, we first collect the events that satisfies the selection criteria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1d223cd-d85b-40bd-bc44-bcdd19fec410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event selection using #0 detector as trigger detector completed.\n",
      "Trigger energy extraction complete.\n",
      "Self interaction ignored. Skipping to next response detector.\n",
      "Secondary selection complete. \n",
      "matrix element (0, 1) evaluation complete\n",
      "Secondary selection complete. \n",
      "matrix element (0, 2) evaluation complete\n",
      "Event selection using #1 detector as trigger detector completed.\n",
      "Trigger energy extraction complete.\n",
      "Secondary selection complete. \n",
      "matrix element (1, 0) evaluation complete\n",
      "Self interaction ignored. Skipping to next response detector.\n",
      "Secondary selection complete. \n",
      "matrix element (1, 2) evaluation complete\n",
      "Event selection using #2 detector as trigger detector completed.\n",
      "Trigger energy extraction complete.\n",
      "Secondary selection complete. \n",
      "matrix element (2, 0) evaluation complete\n",
      "Secondary selection complete. \n",
      "matrix element (2, 1) evaluation complete\n",
      "Self interaction ignored. Skipping to next response detector.\n",
      "[[ 0.         -0.05266973 -0.04685733]\n",
      " [-0.04410721  0.         -0.04803114]\n",
      " [-0.04544804 -0.05624166  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "matrix_iter_limit = 2\n",
    "\n",
    "for j1, trig_detector in enumerate(chn_id):\n",
    "    if j1 > matrix_iter_limit: \n",
    "        break\n",
    "    energy_1, idxs = relevant_events(\n",
    "        table_path=f\"ch{trig_detector}/hit/\",\n",
    "        files = new_hit_list,\n",
    "        ene_dataset=\"cuspEmax_ctc_cal\",\n",
    "        flag_datasets=[\"is_discharge\",\"is_valid_0vbb_old\"],\n",
    "        conditions={\"is_discharge\":False,\"is_valid_0vbb_old\":True},\n",
    "        energy_range=(1500,4500),\n",
    "        return_index=True\n",
    "    )\n",
    "    print(f\"Event selection using #{j1} detector as trigger detector completed.\")\n",
    "    trapTmax_1 = lh5.read(f\"ch{trig_detector}/dsp/trapTmax\",new_dsp_list,idx=idxs).nda\n",
    "    print(\"Trigger energy extraction complete.\")\n",
    "    \n",
    "    for j2 , resp_detector in enumerate(chn_id):\n",
    "        if j1 == j2:\n",
    "            xtalk_matrix[j1,j2]=0\n",
    "            print(\"Self interaction ignored. Skipping to next response detector.\")\n",
    "            continue\n",
    "            \n",
    "        if j2 > matrix_iter_limit:\n",
    "            break\n",
    "        \n",
    "        energy_2 = lh5.read(f\"ch{resp_detector}/hit/cuspEmax_ctc_cal\", new_hit_list, idx=idxs).nda\n",
    "        secondary_selection = (energy_2<100)\n",
    "        secondary_idxs = idxs[secondary_selection]\n",
    "        selected_trapTmax_1=trapTmax_1[secondary_selection]\n",
    "        print(\"Secondary selection complete. \")\n",
    "        table_2 = lh5.read(f\"ch{resp_detector}/dsp/\", new_dsp_list, field_mask=[\"trapTmin\",\"trapTmax\"], idx=secondary_idxs)\n",
    "        trapTmin_2 = table_2[\"trapTmin\"].nda\n",
    "        trapTmax_2 = table_2[\"trapTmax\"].nda\n",
    "        xtalk_matrix[j1,j2] = np.mean(xtalk_element(selected_trapTmax_1,trapTmin_2,baseline_energy[j2]))\n",
    "        print(f\"matrix element {(j1,j2)} evaluation complete\")\n",
    "\n",
    "print(xtalk_matrix[:(matrix_iter_limit+1),:(matrix_iter_limit+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e77d6c-8edd-4d37-9735-98616e18414a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (legend-base)",
   "language": "python",
   "name": "legend-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
